{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feda6758-89d4-46b3-a96a-09c4c4c32e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************************************\n",
    "# (C) Cloudera, Inc. 2020-2025\n",
    "#  All rights reserved.\n",
    "#\n",
    "#  Applicable Open Source License: GNU Affero General Public License v3.0\n",
    "#\n",
    "#  NOTE: Cloudera open source products are modular software products\n",
    "#  made up of hundreds of individual components, each of which was\n",
    "#  individually copyrighted.  Each Cloudera open source product is a\n",
    "#  collective work under U.S. Copyright Law. Your license to use the\n",
    "#  collective work is as provided in your written agreement with\n",
    "#  Cloudera.  Used apart from the collective work, this file is\n",
    "#  licensed for your use pursuant to the open source license\n",
    "#  identified above.\n",
    "#\n",
    "#  This code is provided to you pursuant a written agreement with\n",
    "#  (i) Cloudera, Inc. or (ii) a third-party authorized to distribute\n",
    "#  this code. If you do not have a written agreement with Cloudera nor\n",
    "#  with an authorized and properly licensed third party, you do not\n",
    "#  have any rights to access nor to use this code.\n",
    "#\n",
    "#  Absent a written agreement with Cloudera, Inc. (“Cloudera”) to the\n",
    "#  contrary, A) CLOUDERA PROVIDES THIS CODE TO YOU WITHOUT WARRANTIES OF ANY\n",
    "#  KIND; (B) CLOUDERA DISCLAIMS ANY AND ALL EXPRESS AND IMPLIED\n",
    "#  WARRANTIES WITH RESPECT TO THIS CODE, INCLUDING BUT NOT LIMITED TO\n",
    "#  IMPLIED WARRANTIES OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY AND\n",
    "#  FITNESS FOR A PARTICULAR PURPOSE; (C) CLOUDERA IS NOT LIABLE TO YOU,\n",
    "#  AND WILL NOT DEFEND, INDEMNIFY, NOR HOLD YOU HARMLESS FOR ANY CLAIMS\n",
    "#  ARISING FROM OR RELATED TO THE CODE; AND (D)WITH RESPECT TO YOUR EXERCISE\n",
    "#  OF ANY RIGHTS GRANTED TO YOU FOR THE CODE, CLOUDERA IS NOT LIABLE FOR ANY\n",
    "#  DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, PUNITIVE OR\n",
    "#  CONSEQUENTIAL DAMAGES INCLUDING, BUT NOT LIMITED TO, DAMAGES\n",
    "#  RELATED TO LOST REVENUE, LOST PROFITS, LOSS OF INCOME, LOSS OF\n",
    "#  BUSINESS ADVANTAGE OR UNAVAILABILITY, OR LOSS OR CORRUPTION OF\n",
    "#  DATA.\n",
    "#\n",
    "# #  Author(s): Paul de Fusco\n",
    "#***************************************************************************/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98283b30-fef6-4728-aa42-432dc16782f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from trainingUtil import SimpleTrainingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4ab073-532f-45c7-8ba1-f005da0e7eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40 | Loss = 0.0111 | Acc = 100.0%\n",
      "Epoch  80 | Loss = 0.0029 | Acc = 100.0%\n",
      "Epoch 120 | Loss = 0.0017 | Acc = 100.0%\n",
      "Epoch 160 | Loss = 0.0012 | Acc = 100.0%\n",
      "Epoch 200 | Loss = 0.0008 | Acc = 100.0%\n",
      "\n",
      "Test predictions: [0, 1, 0]\n",
      "Input example shape: (3, 2)\n",
      "Input example (first sample): [-0.66 -1.77]\n"
     ]
    }
   ],
   "source": [
    "pipeline = SimpleTrainingPipeline()\n",
    "X, model, input_example, input_example_tensor = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f72b00-0c72-41d8-8063-8ac8f344e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "def convert_to_onnx(model, input_size=(1,2), onnx_path=\"onnx_model.onnx\"):\n",
    "    \"\"\"Convert PyTorch model to ONNX format\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create dummy input for tracing\n",
    "    dummy_input = torch.randn(input_size, dtype=torch.float32)\n",
    "    \n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"Model exported to ONNX format: {onnx_path}\")\n",
    "    return onnx_path\n",
    "\n",
    "def verify_onnx_model(onnx_path, test_data):\n",
    "    \"\"\"Verify ONNX model works correctly\"\"\"\n",
    "    # Load ONNX model\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    \n",
    "    # Create ONNX Runtime session\n",
    "    ort_session = ort.InferenceSession(onnx_path)\n",
    "    \n",
    "    # Test with a small batch\n",
    "    test_input = test_data[:5].numpy()  # Take first 5 samples\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: test_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "    print(f\"ONNX model verification successful. Output shape: {ort_outputs[0].shape}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83125f0-496d-4765-9598-57221666d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:51:01.998000 105 .local/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 11 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n",
      "W1127 01:51:03.086000 105 .local/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `SimpleClassifier([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `SimpleClassifier([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 11).\n",
      "Failed to convert the model to the target version 11 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdsw/.local/lib/python3.10/site-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "  File \"/home/cdsw/.local/lib/python3.10/site-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "  File \"/home/cdsw/.local/lib/python3.10/site-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "  File \"/home/cdsw/.local/lib/python3.10/site-packages/onnx/version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "RuntimeError: /github/workspace/onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $14 for Relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Model exported to ONNX format: mymodel.onnx\n",
      "ONNX model verification successful. Output shape: (5, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Convert and verify ONNX model\n",
    "onnx_path = \"mymodel.onnx\"\n",
    "convert_to_onnx(model, input_size=(1, 2), onnx_path=onnx_path)\n",
    "verify_onnx_model(onnx_path, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1d3fb2-2e9e-4537-9721-3961a2341d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating run for experiment_id: 0, user_id: cdsw, run_name: None\n",
      "No experiment set using default experiment.Please set experiment using mlflow.set_experiment('<your experiment name>') to avoid using default experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging ONNX model to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'onnx_classifier_notebook'.\n",
      "experiment id 48vs-yru7-jdpt-iidm \n",
      "2025/11/27 01:51:33 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: onnx_classifier_notebook, version 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models logged successfully to MLflow!\n",
      "MLflow Run ID: 8wyv-14qr-bakf-fed7\n",
      "Models logged with input examples and signatures!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '8' of model 'onnx_classifier_notebook'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import onnxmltools\n",
    "from onnxmltools.convert.common.data_types import FloatTensorType\n",
    "\n",
    "REGISTERED_MODEL_NAME_ONNX = \"onnx_classifier_notebook\"\n",
    "with mlflow.start_run() as run:    \n",
    "    # Log the ONNX model to MLflow with input example and signature  \n",
    "    print(\"Logging ONNX model to MLflow...\")\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    mlflow.onnx.log_model(\n",
    "        onnx_model,\n",
    "        \"classifier_onnx\",\n",
    "        registered_model_name=f\"{REGISTERED_MODEL_NAME_ONNX}\",\n",
    "        input_example=input_example\n",
    "    )\n",
    "    \n",
    "    print(\"Models logged successfully to MLflow!\")\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\")\n",
    "    print(\"Models logged with input examples and signatures!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf9cc3-4395-4ec1-a720-fb37c84d8d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
